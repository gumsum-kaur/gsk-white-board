{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/username1437/username1437/blob/main/TensorFlow(Colab)ML-Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQmeJ_WHW7Ah"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-ranking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "6KXiEY9g5jEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data = tfds.load('movielens/100k-ratings', split=\"train\")\n",
        "fetures_data = tfds.load('movielens/100k-movies', split=\"train\")"
      ],
      "metadata": {
        "id": "xkIv9GxH5pJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data = ratings_data.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"user_rating\": x[\"user_rating\"]\n",
        "})"
      ],
      "metadata": {
        "id": "LATauVcC584X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ratings_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSsKHGn46YMS",
        "outputId": "2c8340ac-66df-4788-c07d-43c1ae4ba895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<MapDataset element_spec={'movie_title': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(), dtype=tf.float32, name=None)}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zXtyao5V97_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers \n",
        "feature_data = fetures_data.map(lambda x: x[\"movie_title\"])\n",
        "users = ratings_data.map(lambda x: x[\"user_id\"])\n",
        "\n",
        "user_ids_vocabulary = layers.experimental.preprocessing.StringLookup(\n",
        "    mask_token=None)\n",
        "user_ids_vocabulary.adapt(users.batch(1000))\n",
        "\n",
        "movie_titles_vocabulary = layers.experimental.preprocessing.StringLookup(\n",
        "    mask_token=None)\n",
        "movie_titles_vocabulary.adapt(feature_data.batch(1000))"
      ],
      "metadata": {
        "id": "Zmn9x_NC9bGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_func = lambda x: user_ids_vocabulary(x[\"user_id\"])\n",
        "reduce_func = lambda key, dataset: dataset.batch(100)\n",
        "train = ratings_data.group_by_window(\n",
        "    key_func=key_func, reduce_func=reduce_func, window_size=100)"
      ],
      "metadata": {
        "id": "1DilVpFK-ws6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train)\n",
        "for x in train.take(1):\n",
        "  for key, value in x.items():\n",
        "    print(f\"Shape of {key}: {value.shape}\")\n",
        "    print(f\"Example values of {key}: {value[:5].numpy()}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLVSGzil-_Mk",
        "outputId": "1d212f14-e146-4f0f-8254-7de41e7f67fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_GroupByWindowDataset element_spec={'movie_title': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>\n",
            "Shape of movie_title: (100,)\n",
            "Example values of movie_title: [b'Man Who Would Be King, The (1975)' b'Silence of the Lambs, The (1991)'\n",
            " b'Next Karate Kid, The (1994)' b'2001: A Space Odyssey (1968)'\n",
            " b'Usual Suspects, The (1995)']\n",
            "\n",
            "Shape of user_id: (100,)\n",
            "Example values of user_id: [b'405' b'405' b'405' b'405' b'405']\n",
            "\n",
            "Shape of user_rating: (100,)\n",
            "Example values of user_rating: [1. 4. 1. 5. 5.]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Tuple\n",
        "def _features_and_labels(\n",
        "    x: Dict[str, tf.Tensor]) -> Tuple[Dict[str, tf.Tensor], tf.Tensor]:\n",
        "  labels = x.pop(\"user_rating\")\n",
        "  return x, labels\n",
        "\n",
        "\n",
        "train = train.map(_features_and_labels)\n",
        "\n",
        "train = train.apply(\n",
        "    tf.data.experimental.dense_to_ragged_batch(batch_size=32))"
      ],
      "metadata": {
        "id": "VMCZGW0rB7FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "class RankingModel(Model):\n",
        "\n",
        "  def __init__(self, user_vocab, movie_vocab):\n",
        "    super().__init__()\n",
        "\n",
        "    # Set up user and movie vocabulary and embedding.\n",
        "    self.user_vocab = user_vocab\n",
        "    self.movie_vocab = movie_vocab\n",
        "    self.user_embed = layers.Embedding(user_vocab.vocabulary_size(),\n",
        "                                                64)\n",
        "    self.movie_embed = layers.Embedding(movie_vocab.vocabulary_size(),\n",
        "                                                 64)\n",
        "\n",
        "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "    # Define how the ranking scores are computed: \n",
        "    # Take the dot-product of the user embeddings with the movie embeddings.\n",
        "\n",
        "    embeddings_user= self.user_embed(self.user_vocab(features[\"user_id\"]))\n",
        "    embeddings_movie = self.movie_embed(\n",
        "        self.movie_vocab(features[\"movie_title\"]))\n",
        "\n",
        "    return tf.reduce_sum(embeddings_user * embeddings_movie, axis=2)"
      ],
      "metadata": {
        "id": "XiueuzLqDQgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_ranking as tfr\n",
        "from tensorflow.keras import optimizers\n",
        "model = RankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
        "optimizer = optimizers.Adagrad(0.5)\n",
        "loss = tfr.keras.losses.get(\n",
        "    loss=tfr.keras.losses.RankingLossKey.SOFTMAX_LOSS, ragged=True)\n",
        "eval_metrics = [\n",
        "    tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
        "    tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
        "]\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)"
      ],
      "metadata": {
        "id": "t_EtTVu2Dwzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train, epochs=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKemdhAeD9WF",
        "outputId": "6b6a5289-1356-4f93-9fbd-d0c7a5d07ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "48/48 [==============================] - 5s 79ms/step - loss: 989.3776 - metric/ndcg: 0.9892 - metric/mrr: 1.0000\n",
            "Epoch 2/9\n",
            "48/48 [==============================] - 5s 78ms/step - loss: 989.2220 - metric/ndcg: 0.9903 - metric/mrr: 1.0000\n",
            "Epoch 3/9\n",
            "48/48 [==============================] - 5s 81ms/step - loss: 989.0970 - metric/ndcg: 0.9909 - metric/mrr: 1.0000\n",
            "Epoch 4/9\n",
            "48/48 [==============================] - 6s 91ms/step - loss: 989.0180 - metric/ndcg: 0.9917 - metric/mrr: 1.0000\n",
            "Epoch 5/9\n",
            "48/48 [==============================] - 5s 79ms/step - loss: 988.9356 - metric/ndcg: 0.9925 - metric/mrr: 1.0000\n",
            "Epoch 6/9\n",
            "48/48 [==============================] - 5s 77ms/step - loss: 988.8599 - metric/ndcg: 0.9932 - metric/mrr: 1.0000\n",
            "Epoch 7/9\n",
            "48/48 [==============================] - 5s 78ms/step - loss: 988.8113 - metric/ndcg: 0.9932 - metric/mrr: 1.0000\n",
            "Epoch 8/9\n",
            "48/48 [==============================] - 5s 78ms/step - loss: 988.7804 - metric/ndcg: 0.9938 - metric/mrr: 1.0000\n",
            "Epoch 9/9\n",
            "48/48 [==============================] - 5s 84ms/step - loss: 988.7466 - metric/ndcg: 0.9937 - metric/mrr: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5kJk7l-MQre",
        "outputId": "2f80efff-6dda-44bb-d365-188169d7329a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [989.3775634765625,\n",
              "  989.2220458984375,\n",
              "  989.0970458984375,\n",
              "  989.0180053710938,\n",
              "  988.9356079101562,\n",
              "  988.85986328125,\n",
              "  988.8113403320312,\n",
              "  988.7803955078125,\n",
              "  988.74658203125],\n",
              " 'metric/mrr': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
              " 'metric/ndcg': [0.9892312288284302,\n",
              "  0.9903042912483215,\n",
              "  0.9908571839332581,\n",
              "  0.9917376041412354,\n",
              "  0.9924544095993042,\n",
              "  0.9931710958480835,\n",
              "  0.9932291507720947,\n",
              "  0.9937751293182373,\n",
              "  0.9936739802360535]}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get movie title candidate list.\n",
        "for movie_titles in feature_data.batch(2000):\n",
        "  break\n",
        "\n",
        "# Generate the input for user 42.\n",
        "inputs = {\n",
        "    \"user_id\":\n",
        "        tf.expand_dims(tf.repeat(\"26\", repeats=movie_titles.shape[0]), axis=0),\n",
        "    \"movie_title\":\n",
        "        tf.expand_dims(movie_titles, axis=0)\n",
        "}\n",
        "\n",
        "# Get movie recommendations for user 42.\n",
        "scores = model(inputs)\n",
        "titles = tfr.utils.sort_by_scores(scores,\n",
        "                                  [tf.expand_dims(movie_titles, axis=0)])[0]\n",
        "print(f\"Top 10 recommendations for user 26: {titles[0, :10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHpLIQCuEI3D",
        "outputId": "3ae97374-a653-456c-a7b3-2fa090d78237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 recommendations for user 26: [b'Lawrence of Arabia (1962)' b'Titanic (1997)'\n",
            " b'Maltese Falcon, The (1941)' b'North by Northwest (1959)'\n",
            " b'Blues Brothers, The (1980)' b'Graduate, The (1967)'\n",
            " b'Great Escape, The (1963)' b'Princess Bride, The (1987)'\n",
            " b'Forrest Gump (1994)' b'Legends of the Fall (1994)']\n"
          ]
        }
      ]
    }
  ]
}